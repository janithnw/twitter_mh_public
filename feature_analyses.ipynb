{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import util\n",
    "import mlutils\n",
    "import numpy as np\n",
    "import predictions.models as models\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import pandas as pd\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from brownclustering import brownclusters as bc\n",
    "import mlutils\n",
    "import wordcloud as wc\n",
    "from PIL import Image\n",
    "import generate_wordclouds\n",
    "bc.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = Pipeline([\n",
    "    ('selector', mlutils.ColumnSelector('tweets')),\n",
    "    ('transformer', TfidfVectorizer(min_df=0.01, tokenizer=mlutils.tokenize_only_alphanumeric_tokens))\n",
    "])\n",
    "\n",
    "clusters = Pipeline([\n",
    "    ('selector', mlutils.ColumnSelector('tweets')),\n",
    "    ('transformer', TfidfVectorizer(min_df=0.01, tokenizer=bc.tokenize_and_tag))\n",
    "])\n",
    "\n",
    "cmu = Pipeline([\n",
    "    ('selector', mlutils.POSTagColumnSelector('cmu_pos_tags')),\n",
    "    ('transformer', TfidfVectorizer(tokenizer=mlutils.tknzr.tokenize, min_df=0.01, ngram_range=(1, 3)))\n",
    "])\n",
    "\n",
    "nltk = Pipeline([\n",
    "    ('selector', mlutils.POSTagColumnSelector('nltk_pos_tags')),\n",
    "    ('transformer', TfidfVectorizer(tokenizer=mlutils.tknzr.tokenize, min_df=0.01, ngram_range=(1, 3)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(words, sizes, colors):\n",
    "    mask = Image.open('mask_big.png')\n",
    "    colors = np.array(colors)\n",
    "    colors = colors / max(colors)\n",
    "    word_freqs = {words[i]: sizes[i] for i in range(len(words))}\n",
    "    word_colors = {words[i]: colors[i] for i in range(len(words))}\n",
    "\n",
    "    def color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):\n",
    "        x = word_colors[word]\n",
    "        # v = 128 + (127 / max(abs(colors)) ** 3) * np.power(x, 3)\n",
    "        v = (x - min(colors))/(max(colors) - min(colors))*255\n",
    "        return \"rgb(%d,%d,%d)\" % (v, 0, 255 - v)\n",
    "\n",
    "    cloud = wc.WordCloud(mask=np.array(mask), prefer_horizontal=1.0, color_func=color_func,\n",
    "                         background_color='white')\n",
    "    img = cloud.generate_from_frequencies(word_freqs)\n",
    "    img.to_image().show()\n",
    "    img.to_file('ptsd_clusters.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(pipeline, df):\n",
    "    Y = np.array(df['labels'].astype(int))\n",
    "    X_tfidf = np.array(pipeline.fit_transform(df).todense())\n",
    "    transformer = pipeline.named_steps['transformer']\n",
    "    vocab = transformer.vocabulary_\n",
    "    transformer.use_idf = False\n",
    "    transformer.vocabulary = vocab\n",
    "    X_tf = np.array(pipeline.transform(df).todense())\n",
    "    cohensd = mlutils.compute_cohensd(X_tf, Y)\n",
    "    stats = mlutils.compute_pvals(X_tf, Y)\n",
    "    pvals = [r.pvalue for r in stats]\n",
    "    infogain = mlutils.compute_infogain(X_tfidf, Y)\n",
    "    features = transformer.get_feature_names()\n",
    "    return pd.DataFrame(data=np.array([infogain, cohensd, pvals]).T, columns=['infogain', 'cohensd', 'pvals'], index=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_ptsd = pd.concat([util.load_picke_file(config.CTRL_PTSD_HELD_OUT_FILTERED_DF), util.load_picke_file(config.CTRL_PTSD_FILTERED_DF)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_depr = pd.concat([util.load_picke_file(config.CTRL_DEPR_HELD_OUT_FILTERED_DF), util.load_picke_file(config.CTRL_DEPR_FILTERED_DF)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusters_f_df = compute_stats(clusters, ctrl_depr)\n",
    "sig_df = clusters_f_df.loc[clusters_f_df['pvals'] < 0.05 / len(clusters_f_df)]\n",
    "generate_wordclouds.cluster_usage_word_cloud(ctrl_depr, sig_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_f_df = compute_stats(bow, ctrl_depr)\n",
    "sig_bow_df = bow_f_df.loc[bow_f_df['pvals'] < 0.05 / len(bow_f_df)].sort_values(['cohensd', 'infogain'], ascending=False)\n",
    "sig_bow_df.to_csv('sig_features/ctrl_depr_bow_sig_features.csv')\n",
    "bow_f_df.sort_values(['cohensd', 'infogain'], ascending=False).to_csv('sig_features/ctrl_depr_bow_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_f_df = compute_stats(cmu, ctrl_df)\n",
    "sig_cmu_df = cmu_f_df.loc[cmu_f_df['pvals'] < 0.05 / len(cmu_f_df)].sort_values(['cohensd', 'infogain'], ascending=False)\n",
    "sig_cmu_df.to_csv('sig_features/ctrl_depr_cmu_sig_features.csv')\n",
    "cmu_f_df.to_csv('sig_features/ctrl_depr_cmu_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_f_df = compute_stats(nltk, ctrl_df)\n",
    "sig_nltk_df = nltk_f_df.loc[nltk_f_df['pvals'] < 0.05 / len(nltk_f_df)].sort_values(['cohensd', 'infogain'], ascending=False)\n",
    "sig_nltk_df.to_csv('sig_features/ctrl_depr_nltk_sig_features.csv')\n",
    "nltk_f_df.to_csv('sig_features/ctrl_depr_nltk_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_wordcloud(sig_bow_df.index.values, sig_bow_df['infogain'], sig_bow_df['cohensd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_f_df = compute_stats(clusters, ctrl_ptsd)\n",
    "sig_df = clusters_f_df.loc[np.logical_and(clusters_f_df['pvals'] < 0.05 / len(clusters_f_df), np.logical_or(clusters_f_df['cohensd'] > .4, clusters_f_df['cohensd'] < 0))]\n",
    "generate_wordclouds.cluster_usage_word_cloud(ctrl_ptsd, sig_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_f_df = compute_stats(bow, ctrl_ptsd)\n",
    "sig_bow_df = bow_f_df.loc[bow_f_df['pvals'] < 0.05 / len(bow_f_df)].sort_values(['cohensd', 'infogain'], ascending=False)\n",
    "sig_bow_df.to_csv('sig_features/ctrl_ptsd_bow_sig_features.csv')\n",
    "bow_f_df.sort_values(['cohensd', 'infogain'], ascending=False).to_csv('sig_features/ctrl_ptsd_bow_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_f_df = compute_stats(cmu, ctrl_ptsd)\n",
    "sig_cmu_df = cmu_f_df.loc[cmu_f_df['pvals'] < 0.05 / len(cmu_f_df)].sort_values(['cohensd', 'infogain'], ascending=False)\n",
    "sig_cmu_df.to_csv('sig_features/ctrl_ptsd_cmu_sig_features.csv')\n",
    "cmu_f_df.to_csv('sig_features/ctrl_ptsd_cmu_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_f_df = compute_stats(nltk, ctrl_ptsd)\n",
    "sig_nltk_df = nltk_f_df.loc[nltk_f_df['pvals'] < 0.05 / len(nltk_f_df)].sort_values(['cohensd', 'infogain'], ascending=False)\n",
    "sig_nltk_df.to_csv('sig_features/ctrl_ptsd_nltk_sig_features.csv')\n",
    "nltk_f_df.to_csv('sig_features/ctrl_ptsd_nltk_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_wordcloud(sig_bow_df.index.values, sig_bow_df['infogain'], sig_bow_df['cohensd'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
